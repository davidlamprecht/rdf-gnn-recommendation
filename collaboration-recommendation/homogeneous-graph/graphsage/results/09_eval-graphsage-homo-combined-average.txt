Device: 'cuda'
Epoch: 001, Training Loss: 0.6874
Epoch: 001, Validation Loss: 0.6641
Epoch: 002, Training Loss: 0.6500
Epoch: 002, Validation Loss: 0.6394
Epoch: 003, Training Loss: 0.6224
Epoch: 003, Validation Loss: 0.6185
Epoch: 004, Training Loss: 0.5968
Epoch: 004, Validation Loss: 0.6018
Epoch: 005, Training Loss: 0.5746
Epoch: 005, Validation Loss: 0.5905
Epoch: 006, Training Loss: 0.5578
Epoch: 006, Validation Loss: 0.5816
Epoch: 007, Training Loss: 0.5438
Epoch: 007, Validation Loss: 0.5720
Epoch: 008, Training Loss: 0.5297
Epoch: 008, Validation Loss: 0.5628
Epoch: 009, Training Loss: 0.5166
Epoch: 009, Validation Loss: 0.5562
Epoch: 010, Training Loss: 0.5070
Epoch: 010, Validation Loss: 0.5529
Epoch: 011, Training Loss: 0.5012
Epoch: 011, Validation Loss: 0.5515
Epoch: 012, Training Loss: 0.4973
Epoch: 012, Validation Loss: 0.5505
Epoch: 013, Training Loss: 0.4937
Epoch: 013, Validation Loss: 0.5494
Epoch: 014, Training Loss: 0.4899
Epoch: 014, Validation Loss: 0.5479
Epoch: 015, Training Loss: 0.4862
Epoch: 015, Validation Loss: 0.5459
Epoch: 016, Training Loss: 0.4826
Epoch: 016, Validation Loss: 0.5431
Epoch: 017, Training Loss: 0.4789
Epoch: 017, Validation Loss: 0.5396
Epoch: 018, Training Loss: 0.4753
Epoch: 018, Validation Loss: 0.5362
Epoch: 019, Training Loss: 0.4719
Epoch: 019, Validation Loss: 0.5333
Epoch: 020, Training Loss: 0.4688
Epoch: 020, Validation Loss: 0.5310
Epoch: 021, Training Loss: 0.4659
Epoch: 021, Validation Loss: 0.5292
Epoch: 022, Training Loss: 0.4632
Epoch: 022, Validation Loss: 0.5278
Epoch: 023, Training Loss: 0.4607
Epoch: 023, Validation Loss: 0.5262
Epoch: 024, Training Loss: 0.4583
Epoch: 024, Validation Loss: 0.5245
Epoch: 025, Training Loss: 0.4557
Epoch: 025, Validation Loss: 0.5225
Epoch: 026, Training Loss: 0.4533
Epoch: 026, Validation Loss: 0.5208
Epoch: 027, Training Loss: 0.4511
Epoch: 027, Validation Loss: 0.5194
Epoch: 028, Training Loss: 0.4491
Epoch: 028, Validation Loss: 0.5183
Epoch: 029, Training Loss: 0.4473
Epoch: 029, Validation Loss: 0.5175
Epoch: 030, Training Loss: 0.4455
Epoch: 030, Validation Loss: 0.5168
Epoch: 031, Training Loss: 0.4438
Epoch: 031, Validation Loss: 0.5162
Epoch: 032, Training Loss: 0.4424
Epoch: 032, Validation Loss: 0.5153
Epoch: 033, Training Loss: 0.4410
Epoch: 033, Validation Loss: 0.5140
Epoch: 034, Training Loss: 0.4394
Epoch: 034, Validation Loss: 0.5123
Epoch: 035, Training Loss: 0.4379
Epoch: 035, Validation Loss: 0.5107
Epoch: 036, Training Loss: 0.4363
Epoch: 036, Validation Loss: 0.5092
Epoch: 037, Training Loss: 0.4347
Epoch: 037, Validation Loss: 0.5078
Epoch: 038, Training Loss: 0.4331
Epoch: 038, Validation Loss: 0.5065
Epoch: 039, Training Loss: 0.4314
Epoch: 039, Validation Loss: 0.5051
Epoch: 040, Training Loss: 0.4298
Epoch: 040, Validation Loss: 0.5038
Epoch: 041, Training Loss: 0.4282
Epoch: 041, Validation Loss: 0.5024
Epoch: 042, Training Loss: 0.4267
Epoch: 042, Validation Loss: 0.5012
Epoch: 043, Training Loss: 0.4253
Epoch: 043, Validation Loss: 0.5003
Epoch: 044, Training Loss: 0.4240
Epoch: 044, Validation Loss: 0.4996
Epoch: 045, Training Loss: 0.4228
Epoch: 045, Validation Loss: 0.4991
Epoch: 046, Training Loss: 0.4216
Epoch: 046, Validation Loss: 0.4987
Epoch: 047, Training Loss: 0.4205
Epoch: 047, Validation Loss: 0.4983
Epoch: 048, Training Loss: 0.4195
Epoch: 048, Validation Loss: 0.4979
Epoch: 049, Training Loss: 0.4186
Epoch: 049, Validation Loss: 0.4974
Epoch: 050, Training Loss: 0.4176
Epoch: 050, Validation Loss: 0.4969
Epoch: 051, Training Loss: 0.4167
Epoch: 051, Validation Loss: 0.4964
Epoch: 052, Training Loss: 0.4158
Epoch: 052, Validation Loss: 0.4960
Epoch: 053, Training Loss: 0.4149
Epoch: 053, Validation Loss: 0.4956
Epoch: 054, Training Loss: 0.4139
Epoch: 054, Validation Loss: 0.4951
Epoch: 055, Training Loss: 0.4129
Epoch: 055, Validation Loss: 0.4946
Epoch: 056, Training Loss: 0.4119
Epoch: 056, Validation Loss: 0.4941
Epoch: 057, Training Loss: 0.4109
Epoch: 057, Validation Loss: 0.4935
Epoch: 058, Training Loss: 0.4099
Epoch: 058, Validation Loss: 0.4929
Epoch: 059, Training Loss: 0.4089
Epoch: 059, Validation Loss: 0.4923
Epoch: 060, Training Loss: 0.4080
Epoch: 060, Validation Loss: 0.4917
Epoch: 061, Training Loss: 0.4071
Epoch: 061, Validation Loss: 0.4912
Epoch: 062, Training Loss: 0.4062
Epoch: 062, Validation Loss: 0.4908
Epoch: 063, Training Loss: 0.4054
Epoch: 063, Validation Loss: 0.4904
Epoch: 064, Training Loss: 0.4046
Epoch: 064, Validation Loss: 0.4901
Epoch: 065, Training Loss: 0.4039
Epoch: 065, Validation Loss: 0.4897
Epoch: 066, Training Loss: 0.4031
Epoch: 066, Validation Loss: 0.4895
Epoch: 067, Training Loss: 0.4024
Epoch: 067, Validation Loss: 0.4893
Epoch: 068, Training Loss: 0.4017
Epoch: 068, Validation Loss: 0.4891
Epoch: 069, Training Loss: 0.4010
Epoch: 069, Validation Loss: 0.4889
Epoch: 070, Training Loss: 0.4003
Epoch: 070, Validation Loss: 0.4887
Epoch: 071, Training Loss: 0.3996
Epoch: 071, Validation Loss: 0.4885
Epoch: 072, Training Loss: 0.3990
Epoch: 072, Validation Loss: 0.4883
Epoch: 073, Training Loss: 0.3984
Epoch: 073, Validation Loss: 0.4882
Epoch: 074, Training Loss: 0.3978
Epoch: 074, Validation Loss: 0.4881
Epoch: 075, Training Loss: 0.3972
Epoch: 075, Validation Loss: 0.4880
Epoch: 076, Training Loss: 0.3966
Epoch: 076, Validation Loss: 0.4879
Epoch: 077, Training Loss: 0.3960
Epoch: 077, Validation Loss: 0.4878
Epoch: 078, Training Loss: 0.3955
Epoch: 078, Validation Loss: 0.4878
Epoch: 079, Training Loss: 0.3949
Epoch: 079, Validation Loss: 0.4878
Epoch: 080, Training Loss: 0.3944
Epoch: 080, Validation Loss: 0.4877
Epoch: 081, Training Loss: 0.3938
Epoch: 081, Validation Loss: 0.4877
Epoch: 082, Training Loss: 0.3933
Epoch: 082, Validation Loss: 0.4876
Epoch: 083, Training Loss: 0.3927
Epoch: 083, Validation Loss: 0.4875
Epoch: 084, Training Loss: 0.3922
Epoch: 084, Validation Loss: 0.4874
Epoch: 085, Training Loss: 0.3916
Epoch: 085, Validation Loss: 0.4873
Epoch: 086, Training Loss: 0.3911
Epoch: 086, Validation Loss: 0.4871
Epoch: 087, Training Loss: 0.3905
Epoch: 087, Validation Loss: 0.4870
Epoch: 088, Training Loss: 0.3900
Epoch: 088, Validation Loss: 0.4868
Epoch: 089, Training Loss: 0.3894
Epoch: 089, Validation Loss: 0.4866
Epoch: 090, Training Loss: 0.3889
Epoch: 090, Validation Loss: 0.4864
Epoch: 091, Training Loss: 0.3884
Epoch: 091, Validation Loss: 0.4863
Epoch: 092, Training Loss: 0.3878
Epoch: 092, Validation Loss: 0.4861
Epoch: 093, Training Loss: 0.3873
Epoch: 093, Validation Loss: 0.4860
Epoch: 094, Training Loss: 0.3868
Epoch: 094, Validation Loss: 0.4859
Epoch: 095, Training Loss: 0.3863
Epoch: 095, Validation Loss: 0.4858
Epoch: 096, Training Loss: 0.3857
Epoch: 096, Validation Loss: 0.4857
Epoch: 097, Training Loss: 0.3852
Epoch: 097, Validation Loss: 0.4856
Epoch: 098, Training Loss: 0.3847
Epoch: 098, Validation Loss: 0.4856
Epoch: 099, Training Loss: 0.3842
Epoch: 099, Validation Loss: 0.4855
Epoch: 100, Training Loss: 0.3837
Epoch: 100, Validation Loss: 0.4855
Stopping after 100 Epochs.
Evaluation on Test Data:
Test AUC: 0.8982
Test AP: 0.9226
Test Recall: 0.9078
Test Precision: 0.6570
Test Accuracy: 0.7170
Test F1: 0.7623
The model has 20,672 trainable parameters.
