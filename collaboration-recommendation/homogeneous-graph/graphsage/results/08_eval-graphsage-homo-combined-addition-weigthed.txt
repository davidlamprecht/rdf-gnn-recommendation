Device: 'cuda'
Epoch: 001, Training Loss: 0.6915
Epoch: 001, Validation Loss: 0.6648
Epoch: 002, Training Loss: 0.6507
Epoch: 002, Validation Loss: 0.6394
Epoch: 003, Training Loss: 0.6226
Epoch: 003, Validation Loss: 0.6180
Epoch: 004, Training Loss: 0.5966
Epoch: 004, Validation Loss: 0.6008
Epoch: 005, Training Loss: 0.5739
Epoch: 005, Validation Loss: 0.5893
Epoch: 006, Training Loss: 0.5568
Epoch: 006, Validation Loss: 0.5809
Epoch: 007, Training Loss: 0.5432
Epoch: 007, Validation Loss: 0.5718
Epoch: 008, Training Loss: 0.5294
Epoch: 008, Validation Loss: 0.5625
Epoch: 009, Training Loss: 0.5162
Epoch: 009, Validation Loss: 0.5556
Epoch: 010, Training Loss: 0.5062
Epoch: 010, Validation Loss: 0.5521
Epoch: 011, Training Loss: 0.5002
Epoch: 011, Validation Loss: 0.5506
Epoch: 012, Training Loss: 0.4965
Epoch: 012, Validation Loss: 0.5496
Epoch: 013, Training Loss: 0.4930
Epoch: 013, Validation Loss: 0.5483
Epoch: 014, Training Loss: 0.4891
Epoch: 014, Validation Loss: 0.5469
Epoch: 015, Training Loss: 0.4853
Epoch: 015, Validation Loss: 0.5451
Epoch: 016, Training Loss: 0.4816
Epoch: 016, Validation Loss: 0.5425
Epoch: 017, Training Loss: 0.4780
Epoch: 017, Validation Loss: 0.5391
Epoch: 018, Training Loss: 0.4742
Epoch: 018, Validation Loss: 0.5355
Epoch: 019, Training Loss: 0.4705
Epoch: 019, Validation Loss: 0.5323
Epoch: 020, Training Loss: 0.4672
Epoch: 020, Validation Loss: 0.5297
Epoch: 021, Training Loss: 0.4643
Epoch: 021, Validation Loss: 0.5278
Epoch: 022, Training Loss: 0.4617
Epoch: 022, Validation Loss: 0.5262
Epoch: 023, Training Loss: 0.4592
Epoch: 023, Validation Loss: 0.5247
Epoch: 024, Training Loss: 0.4568
Epoch: 024, Validation Loss: 0.5231
Epoch: 025, Training Loss: 0.4544
Epoch: 025, Validation Loss: 0.5214
Epoch: 026, Training Loss: 0.4520
Epoch: 026, Validation Loss: 0.5198
Epoch: 027, Training Loss: 0.4499
Epoch: 027, Validation Loss: 0.5184
Epoch: 028, Training Loss: 0.4480
Epoch: 028, Validation Loss: 0.5174
Epoch: 029, Training Loss: 0.4462
Epoch: 029, Validation Loss: 0.5165
Epoch: 030, Training Loss: 0.4445
Epoch: 030, Validation Loss: 0.5158
Epoch: 031, Training Loss: 0.4428
Epoch: 031, Validation Loss: 0.5151
Epoch: 032, Training Loss: 0.4413
Epoch: 032, Validation Loss: 0.5141
Epoch: 033, Training Loss: 0.4399
Epoch: 033, Validation Loss: 0.5128
Epoch: 034, Training Loss: 0.4384
Epoch: 034, Validation Loss: 0.5112
Epoch: 035, Training Loss: 0.4368
Epoch: 035, Validation Loss: 0.5096
Epoch: 036, Training Loss: 0.4352
Epoch: 036, Validation Loss: 0.5081
Epoch: 037, Training Loss: 0.4336
Epoch: 037, Validation Loss: 0.5068
Epoch: 038, Training Loss: 0.4320
Epoch: 038, Validation Loss: 0.5055
Epoch: 039, Training Loss: 0.4303
Epoch: 039, Validation Loss: 0.5043
Epoch: 040, Training Loss: 0.4288
Epoch: 040, Validation Loss: 0.5030
Epoch: 041, Training Loss: 0.4272
Epoch: 041, Validation Loss: 0.5017
Epoch: 042, Training Loss: 0.4258
Epoch: 042, Validation Loss: 0.5006
Epoch: 043, Training Loss: 0.4244
Epoch: 043, Validation Loss: 0.4997
Epoch: 044, Training Loss: 0.4232
Epoch: 044, Validation Loss: 0.4990
Epoch: 045, Training Loss: 0.4220
Epoch: 045, Validation Loss: 0.4985
Epoch: 046, Training Loss: 0.4209
Epoch: 046, Validation Loss: 0.4981
Epoch: 047, Training Loss: 0.4199
Epoch: 047, Validation Loss: 0.4977
Epoch: 048, Training Loss: 0.4189
Epoch: 048, Validation Loss: 0.4972
Epoch: 049, Training Loss: 0.4179
Epoch: 049, Validation Loss: 0.4967
Epoch: 050, Training Loss: 0.4170
Epoch: 050, Validation Loss: 0.4962
Epoch: 051, Training Loss: 0.4160
Epoch: 051, Validation Loss: 0.4956
Epoch: 052, Training Loss: 0.4151
Epoch: 052, Validation Loss: 0.4951
Epoch: 053, Training Loss: 0.4141
Epoch: 053, Validation Loss: 0.4946
Epoch: 054, Training Loss: 0.4132
Epoch: 054, Validation Loss: 0.4942
Epoch: 055, Training Loss: 0.4121
Epoch: 055, Validation Loss: 0.4937
Epoch: 056, Training Loss: 0.4111
Epoch: 056, Validation Loss: 0.4932
Epoch: 057, Training Loss: 0.4101
Epoch: 057, Validation Loss: 0.4926
Epoch: 058, Training Loss: 0.4091
Epoch: 058, Validation Loss: 0.4920
Epoch: 059, Training Loss: 0.4082
Epoch: 059, Validation Loss: 0.4914
Epoch: 060, Training Loss: 0.4073
Epoch: 060, Validation Loss: 0.4909
Epoch: 061, Training Loss: 0.4064
Epoch: 061, Validation Loss: 0.4904
Epoch: 062, Training Loss: 0.4055
Epoch: 062, Validation Loss: 0.4901
Epoch: 063, Training Loss: 0.4047
Epoch: 063, Validation Loss: 0.4897
Epoch: 064, Training Loss: 0.4039
Epoch: 064, Validation Loss: 0.4894
Epoch: 065, Training Loss: 0.4031
Epoch: 065, Validation Loss: 0.4891
Epoch: 066, Training Loss: 0.4024
Epoch: 066, Validation Loss: 0.4889
Epoch: 067, Training Loss: 0.4016
Epoch: 067, Validation Loss: 0.4887
Epoch: 068, Training Loss: 0.4009
Epoch: 068, Validation Loss: 0.4886
Epoch: 069, Training Loss: 0.4003
Epoch: 069, Validation Loss: 0.4885
Epoch: 070, Training Loss: 0.3996
Epoch: 070, Validation Loss: 0.4883
Epoch: 071, Training Loss: 0.3990
Epoch: 071, Validation Loss: 0.4882
Epoch: 072, Training Loss: 0.3983
Epoch: 072, Validation Loss: 0.4880
Epoch: 073, Training Loss: 0.3977
Epoch: 073, Validation Loss: 0.4879
Epoch: 074, Training Loss: 0.3971
Epoch: 074, Validation Loss: 0.4878
Epoch: 075, Training Loss: 0.3965
Epoch: 075, Validation Loss: 0.4878
Epoch: 076, Training Loss: 0.3960
Epoch: 076, Validation Loss: 0.4877
Epoch: 077, Training Loss: 0.3954
Epoch: 077, Validation Loss: 0.4876
Epoch: 078, Training Loss: 0.3949
Epoch: 078, Validation Loss: 0.4875
Epoch: 079, Training Loss: 0.3943
Epoch: 079, Validation Loss: 0.4875
Epoch: 080, Training Loss: 0.3937
Epoch: 080, Validation Loss: 0.4874
Epoch: 081, Training Loss: 0.3932
Epoch: 081, Validation Loss: 0.4873
Epoch: 082, Training Loss: 0.3926
Epoch: 082, Validation Loss: 0.4872
Epoch: 083, Training Loss: 0.3921
Epoch: 083, Validation Loss: 0.4871
Epoch: 084, Training Loss: 0.3915
Epoch: 084, Validation Loss: 0.4870
Epoch: 085, Training Loss: 0.3910
Epoch: 085, Validation Loss: 0.4869
Epoch: 086, Training Loss: 0.3904
Epoch: 086, Validation Loss: 0.4867
Epoch: 087, Training Loss: 0.3899
Epoch: 087, Validation Loss: 0.4866
Epoch: 088, Training Loss: 0.3894
Epoch: 088, Validation Loss: 0.4864
Epoch: 089, Training Loss: 0.3888
Epoch: 089, Validation Loss: 0.4863
Epoch: 090, Training Loss: 0.3883
Epoch: 090, Validation Loss: 0.4862
Epoch: 091, Training Loss: 0.3878
Epoch: 091, Validation Loss: 0.4861
Epoch: 092, Training Loss: 0.3872
Epoch: 092, Validation Loss: 0.4860
Epoch: 093, Training Loss: 0.3867
Epoch: 093, Validation Loss: 0.4859
Epoch: 094, Training Loss: 0.3862
Epoch: 094, Validation Loss: 0.4858
Epoch: 095, Training Loss: 0.3857
Epoch: 095, Validation Loss: 0.4857
Epoch: 096, Training Loss: 0.3852
Epoch: 096, Validation Loss: 0.4857
Epoch: 097, Training Loss: 0.3847
Epoch: 097, Validation Loss: 0.4856
Epoch: 098, Training Loss: 0.3842
Epoch: 098, Validation Loss: 0.4855
Epoch: 099, Training Loss: 0.3837
Epoch: 099, Validation Loss: 0.4854
Epoch: 100, Training Loss: 0.3832
Epoch: 100, Validation Loss: 0.4854
Stopping after 100 Epochs.
Evaluation on Test Data:
Test AUC: 0.8984
Test AP: 0.9228
Test Recall: 0.9099
Test Precision: 0.6558
Test Accuracy: 0.7162
Test F1: 0.7623
The model has 20,672 trainable parameters.
