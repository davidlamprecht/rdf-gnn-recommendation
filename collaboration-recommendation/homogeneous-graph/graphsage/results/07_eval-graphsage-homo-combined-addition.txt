Device: 'cuda'
Epoch: 001, Training Loss: 0.9213
Epoch: 001, Validation Loss: 0.7284
Epoch: 002, Training Loss: 0.7125
Epoch: 002, Validation Loss: 0.6483
Epoch: 003, Training Loss: 0.6297
Epoch: 003, Validation Loss: 0.6137
Epoch: 004, Training Loss: 0.5930
Epoch: 004, Validation Loss: 0.5921
Epoch: 005, Training Loss: 0.5676
Epoch: 005, Validation Loss: 0.5759
Epoch: 006, Training Loss: 0.5461
Epoch: 006, Validation Loss: 0.5657
Epoch: 007, Training Loss: 0.5303
Epoch: 007, Validation Loss: 0.5613
Epoch: 008, Training Loss: 0.5207
Epoch: 008, Validation Loss: 0.5581
Epoch: 009, Training Loss: 0.5132
Epoch: 009, Validation Loss: 0.5529
Epoch: 010, Training Loss: 0.5044
Epoch: 010, Validation Loss: 0.5466
Epoch: 011, Training Loss: 0.4953
Epoch: 011, Validation Loss: 0.5418
Epoch: 012, Training Loss: 0.4885
Epoch: 012, Validation Loss: 0.5394
Epoch: 013, Training Loss: 0.4849
Epoch: 013, Validation Loss: 0.5382
Epoch: 014, Training Loss: 0.4826
Epoch: 014, Validation Loss: 0.5366
Epoch: 015, Training Loss: 0.4797
Epoch: 015, Validation Loss: 0.5340
Epoch: 016, Training Loss: 0.4756
Epoch: 016, Validation Loss: 0.5311
Epoch: 017, Training Loss: 0.4710
Epoch: 017, Validation Loss: 0.5286
Epoch: 018, Training Loss: 0.4670
Epoch: 018, Validation Loss: 0.5265
Epoch: 019, Training Loss: 0.4637
Epoch: 019, Validation Loss: 0.5243
Epoch: 020, Training Loss: 0.4608
Epoch: 020, Validation Loss: 0.5217
Epoch: 021, Training Loss: 0.4576
Epoch: 021, Validation Loss: 0.5187
Epoch: 022, Training Loss: 0.4540
Epoch: 022, Validation Loss: 0.5160
Epoch: 023, Training Loss: 0.4507
Epoch: 023, Validation Loss: 0.5140
Epoch: 024, Training Loss: 0.4481
Epoch: 024, Validation Loss: 0.5127
Epoch: 025, Training Loss: 0.4462
Epoch: 025, Validation Loss: 0.5117
Epoch: 026, Training Loss: 0.4445
Epoch: 026, Validation Loss: 0.5108
Epoch: 027, Training Loss: 0.4428
Epoch: 027, Validation Loss: 0.5096
Epoch: 028, Training Loss: 0.4409
Epoch: 028, Validation Loss: 0.5083
Epoch: 029, Training Loss: 0.4389
Epoch: 029, Validation Loss: 0.5071
Epoch: 030, Training Loss: 0.4370
Epoch: 030, Validation Loss: 0.5061
Epoch: 031, Training Loss: 0.4353
Epoch: 031, Validation Loss: 0.5052
Epoch: 032, Training Loss: 0.4338
Epoch: 032, Validation Loss: 0.5044
Epoch: 033, Training Loss: 0.4322
Epoch: 033, Validation Loss: 0.5036
Epoch: 034, Training Loss: 0.4307
Epoch: 034, Validation Loss: 0.5027
Epoch: 035, Training Loss: 0.4291
Epoch: 035, Validation Loss: 0.5019
Epoch: 036, Training Loss: 0.4276
Epoch: 036, Validation Loss: 0.5011
Epoch: 037, Training Loss: 0.4263
Epoch: 037, Validation Loss: 0.5003
Epoch: 038, Training Loss: 0.4250
Epoch: 038, Validation Loss: 0.4994
Epoch: 039, Training Loss: 0.4238
Epoch: 039, Validation Loss: 0.4985
Epoch: 040, Training Loss: 0.4225
Epoch: 040, Validation Loss: 0.4975
Epoch: 041, Training Loss: 0.4212
Epoch: 041, Validation Loss: 0.4966
Epoch: 042, Training Loss: 0.4200
Epoch: 042, Validation Loss: 0.4959
Epoch: 043, Training Loss: 0.4188
Epoch: 043, Validation Loss: 0.4952
Epoch: 044, Training Loss: 0.4177
Epoch: 044, Validation Loss: 0.4947
Epoch: 045, Training Loss: 0.4166
Epoch: 045, Validation Loss: 0.4942
Epoch: 046, Training Loss: 0.4156
Epoch: 046, Validation Loss: 0.4938
Epoch: 047, Training Loss: 0.4147
Epoch: 047, Validation Loss: 0.4935
Epoch: 048, Training Loss: 0.4138
Epoch: 048, Validation Loss: 0.4931
Epoch: 049, Training Loss: 0.4130
Epoch: 049, Validation Loss: 0.4927
Epoch: 050, Training Loss: 0.4122
Epoch: 050, Validation Loss: 0.4921
Epoch: 051, Training Loss: 0.4114
Epoch: 051, Validation Loss: 0.4916
Epoch: 052, Training Loss: 0.4105
Epoch: 052, Validation Loss: 0.4911
Epoch: 053, Training Loss: 0.4097
Epoch: 053, Validation Loss: 0.4906
Epoch: 054, Training Loss: 0.4089
Epoch: 054, Validation Loss: 0.4902
Epoch: 055, Training Loss: 0.4081
Epoch: 055, Validation Loss: 0.4898
Epoch: 056, Training Loss: 0.4073
Epoch: 056, Validation Loss: 0.4895
Epoch: 057, Training Loss: 0.4065
Epoch: 057, Validation Loss: 0.4892
Epoch: 058, Training Loss: 0.4057
Epoch: 058, Validation Loss: 0.4889
Epoch: 059, Training Loss: 0.4049
Epoch: 059, Validation Loss: 0.4886
Epoch: 060, Training Loss: 0.4041
Epoch: 060, Validation Loss: 0.4883
Epoch: 061, Training Loss: 0.4034
Epoch: 061, Validation Loss: 0.4879
Epoch: 062, Training Loss: 0.4026
Epoch: 062, Validation Loss: 0.4876
Epoch: 063, Training Loss: 0.4019
Epoch: 063, Validation Loss: 0.4874
Epoch: 064, Training Loss: 0.4013
Epoch: 064, Validation Loss: 0.4872
Epoch: 065, Training Loss: 0.4006
Epoch: 065, Validation Loss: 0.4871
Epoch: 066, Training Loss: 0.4000
Epoch: 066, Validation Loss: 0.4869
Epoch: 067, Training Loss: 0.3993
Epoch: 067, Validation Loss: 0.4868
Epoch: 068, Training Loss: 0.3987
Epoch: 068, Validation Loss: 0.4867
Epoch: 069, Training Loss: 0.3981
Epoch: 069, Validation Loss: 0.4866
Epoch: 070, Training Loss: 0.3975
Epoch: 070, Validation Loss: 0.4865
Epoch: 071, Training Loss: 0.3969
Epoch: 071, Validation Loss: 0.4864
Epoch: 072, Training Loss: 0.3963
Epoch: 072, Validation Loss: 0.4863
Epoch: 073, Training Loss: 0.3957
Epoch: 073, Validation Loss: 0.4863
Epoch: 074, Training Loss: 0.3951
Epoch: 074, Validation Loss: 0.4862
Epoch: 075, Training Loss: 0.3945
Epoch: 075, Validation Loss: 0.4862
Epoch: 076, Training Loss: 0.3939
Epoch: 076, Validation Loss: 0.4861
Epoch: 077, Training Loss: 0.3933
Epoch: 077, Validation Loss: 0.4861
Epoch: 078, Training Loss: 0.3927
Epoch: 078, Validation Loss: 0.4860
Epoch: 079, Training Loss: 0.3922
Epoch: 079, Validation Loss: 0.4860
Epoch: 080, Training Loss: 0.3916
Epoch: 080, Validation Loss: 0.4860
Epoch: 081, Training Loss: 0.3911
Epoch: 081, Validation Loss: 0.4859
Epoch: 082, Training Loss: 0.3905
Epoch: 082, Validation Loss: 0.4859
Epoch: 083, Training Loss: 0.3900
Epoch: 083, Validation Loss: 0.4858
Epoch: 084, Training Loss: 0.3895
Epoch: 084, Validation Loss: 0.4857
Epoch: 085, Training Loss: 0.3890
Epoch: 085, Validation Loss: 0.4856
Epoch: 086, Training Loss: 0.3884
Epoch: 086, Validation Loss: 0.4856
Epoch: 087, Training Loss: 0.3879
Epoch: 087, Validation Loss: 0.4855
Epoch: 088, Training Loss: 0.3874
Epoch: 088, Validation Loss: 0.4854
Epoch: 089, Training Loss: 0.3869
Epoch: 089, Validation Loss: 0.4853
Epoch: 090, Training Loss: 0.3864
Epoch: 090, Validation Loss: 0.4852
Epoch: 091, Training Loss: 0.3859
Epoch: 091, Validation Loss: 0.4852
Epoch: 092, Training Loss: 0.3854
Epoch: 092, Validation Loss: 0.4851
Epoch: 093, Training Loss: 0.3849
Epoch: 093, Validation Loss: 0.4850
Epoch: 094, Training Loss: 0.3844
Epoch: 094, Validation Loss: 0.4850
Epoch: 095, Training Loss: 0.3840
Epoch: 095, Validation Loss: 0.4849
Epoch: 096, Training Loss: 0.3835
Epoch: 096, Validation Loss: 0.4849
Epoch: 097, Training Loss: 0.3830
Epoch: 097, Validation Loss: 0.4848
Epoch: 098, Training Loss: 0.3825
Epoch: 098, Validation Loss: 0.4848
Epoch: 099, Training Loss: 0.3821
Epoch: 099, Validation Loss: 0.4848
Epoch: 100, Training Loss: 0.3816
Epoch: 100, Validation Loss: 0.4847
Stopping after 100 Epochs.
Evaluation on Test Data:
Test AUC: 0.9021
Test AP: 0.9243
Test Recall: 0.9135
Test Precision: 0.6585
Test Accuracy: 0.7198
Test F1: 0.7653
The model has 20,672 trainable parameters.
