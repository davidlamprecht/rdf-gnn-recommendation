Device: 'cuda'
Epoch: 001, Training Loss: 4.0140
Epoch: 001, Validation Loss: 2.5769
Epoch: 002, Training Loss: 2.6583
Epoch: 002, Validation Loss: 1.7286
Epoch: 003, Training Loss: 1.7567
Epoch: 003, Validation Loss: 1.2047
Epoch: 004, Training Loss: 1.2034
Epoch: 004, Validation Loss: 0.9157
Epoch: 005, Training Loss: 0.8992
Epoch: 005, Validation Loss: 0.7728
Epoch: 006, Training Loss: 0.7496
Epoch: 006, Validation Loss: 0.7033
Epoch: 007, Training Loss: 0.6768
Epoch: 007, Validation Loss: 0.6625
Epoch: 008, Training Loss: 0.6335
Epoch: 008, Validation Loss: 0.6315
Epoch: 009, Training Loss: 0.5998
Epoch: 009, Validation Loss: 0.6049
Epoch: 010, Training Loss: 0.5709
Epoch: 010, Validation Loss: 0.5830
Epoch: 011, Training Loss: 0.5471
Epoch: 011, Validation Loss: 0.5661
Epoch: 012, Training Loss: 0.5293
Epoch: 012, Validation Loss: 0.5543
Epoch: 013, Training Loss: 0.5170
Epoch: 013, Validation Loss: 0.5468
Epoch: 014, Training Loss: 0.5093
Epoch: 014, Validation Loss: 0.5423
Epoch: 015, Training Loss: 0.5046
Epoch: 015, Validation Loss: 0.5394
Epoch: 016, Training Loss: 0.5013
Epoch: 016, Validation Loss: 0.5372
Epoch: 017, Training Loss: 0.4987
Epoch: 017, Validation Loss: 0.5352
Epoch: 018, Training Loss: 0.4963
Epoch: 018, Validation Loss: 0.5332
Epoch: 019, Training Loss: 0.4939
Epoch: 019, Validation Loss: 0.5314
Epoch: 020, Training Loss: 0.4915
Epoch: 020, Validation Loss: 0.5296
Epoch: 021, Training Loss: 0.4892
Epoch: 021, Validation Loss: 0.5279
Epoch: 022, Training Loss: 0.4870
Epoch: 022, Validation Loss: 0.5262
Epoch: 023, Training Loss: 0.4848
Epoch: 023, Validation Loss: 0.5246
Epoch: 024, Training Loss: 0.4825
Epoch: 024, Validation Loss: 0.5229
Epoch: 025, Training Loss: 0.4802
Epoch: 025, Validation Loss: 0.5212
Epoch: 026, Training Loss: 0.4779
Epoch: 026, Validation Loss: 0.5197
Epoch: 027, Training Loss: 0.4756
Epoch: 027, Validation Loss: 0.5182
Epoch: 028, Training Loss: 0.4733
Epoch: 028, Validation Loss: 0.5168
Epoch: 029, Training Loss: 0.4712
Epoch: 029, Validation Loss: 0.5154
Epoch: 030, Training Loss: 0.4691
Epoch: 030, Validation Loss: 0.5140
Epoch: 031, Training Loss: 0.4671
Epoch: 031, Validation Loss: 0.5125
Epoch: 032, Training Loss: 0.4650
Epoch: 032, Validation Loss: 0.5110
Epoch: 033, Training Loss: 0.4631
Epoch: 033, Validation Loss: 0.5095
Epoch: 034, Training Loss: 0.4612
Epoch: 034, Validation Loss: 0.5080
Epoch: 035, Training Loss: 0.4594
Epoch: 035, Validation Loss: 0.5066
Epoch: 036, Training Loss: 0.4577
Epoch: 036, Validation Loss: 0.5053
Epoch: 037, Training Loss: 0.4560
Epoch: 037, Validation Loss: 0.5041
Epoch: 038, Training Loss: 0.4544
Epoch: 038, Validation Loss: 0.5029
Epoch: 039, Training Loss: 0.4528
Epoch: 039, Validation Loss: 0.5019
Epoch: 040, Training Loss: 0.4512
Epoch: 040, Validation Loss: 0.5010
Epoch: 041, Training Loss: 0.4496
Epoch: 041, Validation Loss: 0.5001
Epoch: 042, Training Loss: 0.4480
Epoch: 042, Validation Loss: 0.4993
Epoch: 043, Training Loss: 0.4465
Epoch: 043, Validation Loss: 0.4985
Epoch: 044, Training Loss: 0.4451
Epoch: 044, Validation Loss: 0.4977
Epoch: 045, Training Loss: 0.4437
Epoch: 045, Validation Loss: 0.4969
Epoch: 046, Training Loss: 0.4424
Epoch: 046, Validation Loss: 0.4960
Epoch: 047, Training Loss: 0.4411
Epoch: 047, Validation Loss: 0.4951
Epoch: 048, Training Loss: 0.4399
Epoch: 048, Validation Loss: 0.4943
Epoch: 049, Training Loss: 0.4387
Epoch: 049, Validation Loss: 0.4935
Epoch: 050, Training Loss: 0.4375
Epoch: 050, Validation Loss: 0.4927
Epoch: 051, Training Loss: 0.4364
Epoch: 051, Validation Loss: 0.4920
Epoch: 052, Training Loss: 0.4354
Epoch: 052, Validation Loss: 0.4913
Epoch: 053, Training Loss: 0.4344
Epoch: 053, Validation Loss: 0.4908
Epoch: 054, Training Loss: 0.4334
Epoch: 054, Validation Loss: 0.4903
Epoch: 055, Training Loss: 0.4324
Epoch: 055, Validation Loss: 0.4899
Epoch: 056, Training Loss: 0.4315
Epoch: 056, Validation Loss: 0.4895
Epoch: 057, Training Loss: 0.4307
Epoch: 057, Validation Loss: 0.4892
Epoch: 058, Training Loss: 0.4298
Epoch: 058, Validation Loss: 0.4889
Epoch: 059, Training Loss: 0.4290
Epoch: 059, Validation Loss: 0.4886
Epoch: 060, Training Loss: 0.4282
Epoch: 060, Validation Loss: 0.4884
Epoch: 061, Training Loss: 0.4274
Epoch: 061, Validation Loss: 0.4882
Epoch: 062, Training Loss: 0.4267
Epoch: 062, Validation Loss: 0.4880
Epoch: 063, Training Loss: 0.4260
Epoch: 063, Validation Loss: 0.4878
Epoch: 064, Training Loss: 0.4253
Epoch: 064, Validation Loss: 0.4876
Epoch: 065, Training Loss: 0.4246
Epoch: 065, Validation Loss: 0.4874
Epoch: 066, Training Loss: 0.4240
Epoch: 066, Validation Loss: 0.4872
Epoch: 067, Training Loss: 0.4234
Epoch: 067, Validation Loss: 0.4869
Epoch: 068, Training Loss: 0.4227
Epoch: 068, Validation Loss: 0.4867
Epoch: 069, Training Loss: 0.4222
Epoch: 069, Validation Loss: 0.4865
Epoch: 070, Training Loss: 0.4216
Epoch: 070, Validation Loss: 0.4863
Epoch: 071, Training Loss: 0.4210
Epoch: 071, Validation Loss: 0.4860
Epoch: 072, Training Loss: 0.4205
Epoch: 072, Validation Loss: 0.4858
Epoch: 073, Training Loss: 0.4199
Epoch: 073, Validation Loss: 0.4856
Epoch: 074, Training Loss: 0.4194
Epoch: 074, Validation Loss: 0.4854
Epoch: 075, Training Loss: 0.4189
Epoch: 075, Validation Loss: 0.4852
Epoch: 076, Training Loss: 0.4183
Epoch: 076, Validation Loss: 0.4850
Epoch: 077, Training Loss: 0.4178
Epoch: 077, Validation Loss: 0.4848
Epoch: 078, Training Loss: 0.4173
Epoch: 078, Validation Loss: 0.4847
Epoch: 079, Training Loss: 0.4168
Epoch: 079, Validation Loss: 0.4845
Epoch: 080, Training Loss: 0.4164
Epoch: 080, Validation Loss: 0.4844
Epoch: 081, Training Loss: 0.4159
Epoch: 081, Validation Loss: 0.4842
Epoch: 082, Training Loss: 0.4154
Epoch: 082, Validation Loss: 0.4841
Epoch: 083, Training Loss: 0.4149
Epoch: 083, Validation Loss: 0.4840
Epoch: 084, Training Loss: 0.4145
Epoch: 084, Validation Loss: 0.4838
Epoch: 085, Training Loss: 0.4140
Epoch: 085, Validation Loss: 0.4837
Epoch: 086, Training Loss: 0.4136
Epoch: 086, Validation Loss: 0.4835
Epoch: 087, Training Loss: 0.4132
Epoch: 087, Validation Loss: 0.4834
Epoch: 088, Training Loss: 0.4127
Epoch: 088, Validation Loss: 0.4833
Epoch: 089, Training Loss: 0.4123
Epoch: 089, Validation Loss: 0.4831
Epoch: 090, Training Loss: 0.4119
Epoch: 090, Validation Loss: 0.4830
Epoch: 091, Training Loss: 0.4115
Epoch: 091, Validation Loss: 0.4829
Epoch: 092, Training Loss: 0.4111
Epoch: 092, Validation Loss: 0.4828
Epoch: 093, Training Loss: 0.4107
Epoch: 093, Validation Loss: 0.4827
Epoch: 094, Training Loss: 0.4103
Epoch: 094, Validation Loss: 0.4826
Epoch: 095, Training Loss: 0.4099
Epoch: 095, Validation Loss: 0.4825
Epoch: 096, Training Loss: 0.4096
Epoch: 096, Validation Loss: 0.4824
Epoch: 097, Training Loss: 0.4092
Epoch: 097, Validation Loss: 0.4824
Epoch: 098, Training Loss: 0.4088
Epoch: 098, Validation Loss: 0.4823
Epoch: 099, Training Loss: 0.4084
Epoch: 099, Validation Loss: 0.4823
Epoch: 100, Training Loss: 0.4081
Epoch: 100, Validation Loss: 0.4822
Stopping after 100 Epochs.
Evaluation on Test Data:
Test AUC: 0.8879
Test AP: 0.9097
Test Recall: 0.8923
Test Precision: 0.6490
Test Accuracy: 0.7048
Test F1: 0.7514
The model has 16,832 trainable parameters.
